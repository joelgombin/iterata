"""
Templates pour la gÃ©nÃ©ration de Claude Skills
"""

from typing import List, Dict, Any
from datetime import datetime


class SkillTemplate:
    """Template pour gÃ©nÃ©rer SKILL.md"""

    def generate_skill_md(
        self,
        name: str,
        total_corrections: int,
        pattern_count: int,
        top_patterns: List[Any],
        automatable_patterns: List[Any],
        problematic_fields: List[Any],
        transformations: List[Dict[str, Any]],
    ) -> str:
        """GÃ©nÃ¨re le contenu principal de SKILL.md"""

        # Section patterns rÃ©currents
        patterns_section = self._generate_patterns_section(top_patterns)

        # Section champs problÃ©matiques
        fields_section = self._generate_fields_section(problematic_fields)

        # Section transformations
        transformations_section = self._generate_transformations_section(transformations)

        # Section patterns automatisables
        automatable_section = self._generate_automatable_section(automatable_patterns)

        return f"""---
name: {name}
description: Expert knowledge from {total_corrections} human corrections. Specialized in document extraction with learned business rules and common error patterns.
version: 1.0.0
generated: {datetime.now().isoformat()}
patterns_detected: {pattern_count}
---

# {name.replace('-', ' ').title()}

**Generated**: {datetime.now().strftime("%Y-%m-%d %H:%M UTC")}
**Based on**: {total_corrections} corrections across {pattern_count} identified patterns

## When to use this skill

This skill should be used when:
- Extracting structured data from documents
- Validating extraction outputs from ML models
- Applying learned business rules to improve accuracy
- Handling common format normalization issues
- Reviewing low-confidence predictions

## Overview

This skill encapsulates knowledge from {total_corrections} human corrections, revealing systematic patterns in extraction errors. The patterns have been analyzed and categorized to help improve future extractions.

### Key Insights

- **{pattern_count} distinct patterns** identified across corrections
- **{len(automatable_patterns)} patterns** with high automation potential (>70%)
- **{len(problematic_fields)} fields** require special attention
- **{len(transformations)} transformation types** commonly needed

{patterns_section}

{fields_section}

{transformations_section}

{automatable_section}

## Validation workflow

Follow this workflow when processing documents:

1. **Extract** raw data from document using your standard extraction pipeline
2. **Normalize** formats using the transformation patterns documented above
3. **Validate** against business rules in the `rules/` directory
4. **Apply corrections** from high-confidence automatable patterns
5. **Flag** uncertain fields (low confidence or unusual values) for human review
6. **Return** validated output with confidence scores for each field

## Reference materials

- **Business rules**: See `rules/` directory for category-specific validation rules
- **Example corrections**: See `examples/corrections.json` for representative examples
- **Pattern examples**: See `examples/patterns.json` for pattern-specific examples
- **Validation script**: Use `scripts/validate_extraction.py` for automated validation

## Usage

### With Claude Code

Install this skill in your Claude Code skills directory:

```bash
cp -r . ~/.claude/skills/{name}
```

Then invoke it during document extraction tasks.

### Standalone validation

Run the validation script on extraction results:

```bash
python scripts/validate_extraction.py <input.json>
```

### Integration in your pipeline

```python
from iterata import CorrectionLogger
import json

# Load the skill's rules
with open('{name}/examples/patterns.json') as f:
    patterns = json.load(f)

# Apply learned corrections
# ... your integration code here
```

## Continuous improvement

This skill improves over time as more corrections are logged:

1. Continue logging corrections using iterata
2. Regenerate the skill when significant new patterns emerge
3. Review the `rules/` directory for new business logic
4. Update your extraction pipeline based on insights

## Version history

- v1.0.0 ({datetime.now().strftime("%Y-%m-%d")}): Initial generation from {total_corrections} corrections

---

*Generated by [iterata](https://github.com/joelgombin/iterata) - Learn from corrections to improve ML models*
"""

    def _generate_patterns_section(self, patterns: List[Any]) -> str:
        """GÃ©nÃ¨re la section des top patterns"""
        if not patterns:
            return ""

        section = "## Top recurring patterns\n\n"
        section += "These are the most frequent and impactful error patterns identified:\n\n"

        for i, pattern in enumerate(patterns, 1):
            impact_emoji = {"high": "ðŸ”´", "medium": "ðŸŸ¡", "low": "ðŸŸ¢"}.get(
                pattern.impact, "âšª"
            )

            section += f"### {i}. {pattern.description}\n\n"
            section += f"**Category**: `{pattern.category.value}`  \n"
            section += f"**Impact**: {impact_emoji} {pattern.impact}  \n"
            section += f"**Frequency**: {pattern.frequency} occurrences  \n"
            section += f"**Automation potential**: {pattern.automation_potential:.0%}  \n"
            section += f"**First seen**: {pattern.first_seen.strftime('%Y-%m-%d')}  \n"
            section += f"**Last seen**: {pattern.last_seen.strftime('%Y-%m-%d')}  \n"
            section += "\n"

            # Ajout de guidance si le pattern est automatisable
            if pattern.automation_potential >= 0.7:
                section += (
                    "âœ¨ **High automation potential** - Consider implementing "
                    "automatic correction for this pattern.\n\n"
                )

        return section

    def _generate_fields_section(self, fields: List[Any]) -> str:
        """GÃ©nÃ¨re la section des champs problÃ©matiques"""
        if not fields:
            return ""

        section = "## Fields requiring special attention\n\n"
        section += "These fields have the highest correction rates:\n\n"

        for field in fields:
            section += f"- **{field.description}**  \n"
            section += f"  Corrections: {field.frequency} | Impact: {field.impact}\n"

        section += "\n"
        return section

    def _generate_transformations_section(self, transformations: List[Dict]) -> str:
        """GÃ©nÃ¨re la section des transformations"""
        if not transformations:
            return ""

        section = "## Common transformations\n\n"
        section += "These transformation patterns occur frequently:\n\n"

        for transfo in transformations:
            section += f"### {transfo['pattern'].replace('_', ' ').title()}\n\n"
            section += f"**Frequency**: {transfo['frequency']} times\n\n"

            if transfo.get("examples"):
                section += "**Examples**:\n"
                for ex in transfo["examples"][:2]:
                    section += f"- `{ex['original']}` â†’ `{ex['corrected']}`"
                    if ex.get("field"):
                        section += f" (field: `{ex['field']}`)"
                    section += "\n"
                section += "\n"

        return section

    def _generate_automatable_section(self, patterns: List[Any]) -> str:
        """GÃ©nÃ¨re la section des patterns automatisables"""
        if not patterns:
            return ""

        section = "## High-confidence automatable patterns\n\n"
        section += (
            "These patterns have high automation potential and should be "
            "implemented as automatic corrections:\n\n"
        )

        for pattern in patterns:
            section += f"- **{pattern.description}**  \n"
            section += f"  Automation potential: {pattern.automation_potential:.0%} | "
            section += f"Frequency: {pattern.frequency}\n"

        section += "\n"
        return section


class RuleTemplate:
    """Template pour gÃ©nÃ©rer les rÃ¨gles mÃ©tier"""

    def generate_rule(
        self, category: str, corrections: List[Any], patterns: List[Any]
    ) -> str:
        """GÃ©nÃ¨re une rÃ¨gle mÃ©tier pour une catÃ©gorie"""

        # Extrait des exemples reprÃ©sentatifs
        examples = corrections[:5]

        return f"""# {category.replace('_', ' ').title()} Rules

**Category**: `{category}`
**Total corrections**: {len(corrections)}
**Patterns identified**: {len(patterns)}

## Description

This document describes the business rules and validation logic learned from human corrections in the **{category}** category.

## Identified patterns

{self._format_patterns(patterns)}

## Validation rules

Based on the corrections in this category, apply the following rules:

{self._generate_validation_rules(category, corrections, patterns)}

## Examples

### Correction examples

{self._format_examples(examples)}

## Implementation guidance

When implementing these rules in your extraction pipeline:

1. Apply validation after initial extraction
2. Flag violations for review rather than auto-correcting (unless high confidence)
3. Log all rule applications for continuous improvement
4. Monitor rule effectiveness and update as needed

## Notes

- These rules are generated from human corrections and may evolve
- Always validate against your specific business requirements
- Consider the context and document type when applying rules

---

*Generated by iterata on {datetime.now().strftime("%Y-%m-%d %H:%M UTC")}*
"""

    def _format_patterns(self, patterns: List[Any]) -> str:
        """Formate la liste des patterns"""
        if not patterns:
            return "_No specific patterns identified for this category._\n"

        result = ""
        for pattern in patterns:
            result += f"- **{pattern.description}**  \n"
            result += f"  Frequency: {pattern.frequency}, Impact: {pattern.impact}, "
            result += f"Automation: {pattern.automation_potential:.0%}\n"

        return result

    def _generate_validation_rules(
        self, category: str, corrections: List[Any], patterns: List[Any]
    ) -> str:
        """GÃ©nÃ¨re les rÃ¨gles de validation spÃ©cifiques"""

        # Logique basique - peut Ãªtre Ã©tendue
        if category == "format_error":
            return """
### Format validation

- Ensure decimal separators use dots (.) not commas (,)
- Validate date formats follow ISO 8601 (YYYY-MM-DD)
- Check that numeric values don't contain thousands separators
- Verify currency symbols are consistent
"""
        elif category == "business_rule":
            return """
### Business logic validation

- Verify completeness of entity names (full legal names, not abbreviations)
- Check that required fields are not empty
- Validate field values against known business constraints
- Cross-reference related fields for consistency
"""
        else:
            return f"""
### {category.replace('_', ' ').title()} validation

- Review values against expected patterns
- Flag anomalies for human review
- Apply learned transformations where applicable
"""

    def _format_examples(self, examples: List[Any]) -> str:
        """Formate les exemples de corrections"""
        if not examples:
            return "_No examples available._\n"

        result = ""
        for i, ex in enumerate(examples, 1):
            result += f"{i}. **{ex.field_path}**\n"
            result += f"   - Original: `{ex.original_value}`\n"
            result += f"   - Corrected: `{ex.corrected_value}`\n"
            if ex.context.get("description"):
                result += f"   - Reason: {ex.context['description']}\n"
            result += "\n"

        return result


class ExampleTemplate:
    """Template pour gÃ©nÃ©rer les exemples JSON"""

    def generate_correction_examples(self, corrections: List[Any]) -> List[Dict]:
        """GÃ©nÃ¨re des exemples gÃ©nÃ©raux de corrections"""
        return [
            {
                "field": corr.field_path,
                "original": corr.original_value,
                "corrected": corr.corrected_value,
                "reason": corr.context.get("description", ""),
                "document_id": corr.document_id,
                "correction_id": corr.correction_id,
            }
            for corr in corrections
        ]

    def generate_pattern_examples(
        self, examples_by_pattern: Dict[str, List[Any]], patterns: List[Any]
    ) -> Dict[str, Any]:
        """GÃ©nÃ¨re des exemples groupÃ©s par pattern"""
        result = {}

        for pattern in patterns:
            if pattern.pattern_id in examples_by_pattern:
                corrections = examples_by_pattern[pattern.pattern_id]
                result[pattern.pattern_id] = {
                    "description": pattern.description,
                    "category": pattern.category.value,
                    "frequency": pattern.frequency,
                    "automation_potential": pattern.automation_potential,
                    "examples": [
                        {
                            "original": c.original_value,
                            "corrected": c.corrected_value,
                            "field": c.field_path,
                        }
                        for c in corrections
                    ],
                }

        return result


class ValidationScriptTemplate:
    """Template pour gÃ©nÃ©rer le script de validation"""

    def generate_validation_script(self, transformations: List[Dict]) -> str:
        """GÃ©nÃ¨re un script Python de validation"""

        # GÃ©nÃ¨re les fonctions de transformation
        transform_functions = self._generate_transform_functions(transformations)

        return f'''#!/usr/bin/env python3
"""
Validation script for extraction results

This script applies learned correction patterns to validate and fix
common extraction errors.

Usage:
    python validate_extraction.py <input.json>
"""

import sys
import json
from typing import Any, Dict


{transform_functions}


def validate_extraction(data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Validate and correct extraction data based on learned patterns.

    Args:
        data: Extracted data to validate

    Returns:
        Validated and corrected data
    """
    corrected = data.copy()
    corrections_applied = []

    # Apply transformations to each field
    for field, value in data.items():
        if isinstance(value, str):
            original = value

            # Apply all transformation functions
            value = normalize_decimal_separator(value)
            value = normalize_date_format(value)
            value = remove_thousands_separator(value)

            if value != original:
                corrections_applied.append({{
                    "field": field,
                    "original": original,
                    "corrected": value
                }})

            corrected[field] = value

    return {{
        "data": corrected,
        "corrections_applied": corrections_applied,
        "corrections_count": len(corrections_applied)
    }}


def main():
    if len(sys.argv) < 2:
        print("Usage: python validate_extraction.py <input.json>")
        sys.exit(1)

    # Load input
    with open(sys.argv[1]) as f:
        data = json.load(f)

    # Validate
    result = validate_extraction(data)

    # Output
    print(json.dumps(result, indent=2, ensure_ascii=False))

    if result["corrections_count"] > 0:
        print(f"\\nâœ“ Applied {{result['corrections_count']}} corrections", file=sys.stderr)


if __name__ == "__main__":
    main()
'''

    def _generate_transform_functions(self, transformations: List[Dict]) -> str:
        """GÃ©nÃ¨re les fonctions de transformation"""
        return """
def normalize_decimal_separator(value: str) -> str:
    \"\"\"Convert comma decimal separator to dot.\"\"\"
    # Only if it looks like a decimal number
    if ',' in value and value.replace(',', '').replace('.', '').isdigit():
        return value.replace(',', '.')
    return value


def normalize_date_format(value: str) -> str:
    \"\"\"Convert dates to ISO 8601 format (YYYY-MM-DD).\"\"\"
    # Basic date pattern detection and conversion
    import re

    # DD/MM/YYYY -> YYYY-MM-DD
    match = re.match(r'(\\d{{2}})/(\\d{{2}})/(\\d{{4}})', value)
    if match:
        day, month, year = match.groups()
        return f"{{year}}-{{month}}-{{day}}"

    return value


def remove_thousands_separator(value: str) -> str:
    \"\"\"Remove thousands separators from numbers.\"\"\"
    # Remove spaces and commas used as thousands separators
    if value.replace(' ', '').replace(',', '').replace('.', '').isdigit():
        # Be careful not to remove decimal separators
        if '.' in value and value.count('.') == 1:
            parts = value.split('.')
            parts[0] = parts[0].replace(',', '').replace(' ', '')
            return '.'.join(parts)
        return value.replace(',', '').replace(' ', '')
    return value
"""


class ReadmeTemplate:
    """Template pour gÃ©nÃ©rer le README de la skill"""

    def generate_readme(
        self,
        skill_name: str,
        total_corrections: int,
        pattern_count: int,
        high_impact_count: int,
        automatable_count: int,
    ) -> str:
        """GÃ©nÃ¨re le README"""
        return f"""# {skill_name.replace('-', ' ').title()} Skill

This Claude Skill was automatically generated by [iterata](https://github.com/joelgombin/iterata) from {total_corrections} human corrections.

## Overview

- **Total corrections analyzed**: {total_corrections}
- **Patterns identified**: {pattern_count}
- **High-impact patterns**: {high_impact_count}
- **Automatable patterns**: {automatable_count}

## Contents

- `SKILL.md` - Main skill documentation with all patterns and guidance
- `rules/` - Category-specific validation rules
- `examples/` - JSON examples for few-shot learning
- `scripts/` - Validation and utility scripts

## Usage

### With Claude Code

Copy this skill to your Claude Code skills directory:

```bash
cp -r {skill_name} ~/.claude/skills/
```

Then invoke it during document extraction tasks.

### Standalone

Use the validation script on your extraction results:

```bash
python scripts/validate_extraction.py input.json > output.json
```

## Updating this skill

As you log more corrections with iterata, regenerate this skill:

```python
from iterata import CorrectionLoop

loop = CorrectionLoop(base_path="./corrections")
loop.generate_skill(skill_path="./{skill_name}")
```

## Structure

```
{skill_name}/
â”œâ”€â”€ SKILL.md              # Main skill documentation
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ rules/                # Business rules by category
â”‚   â”œâ”€â”€ format-errors.md
â”‚   â”œâ”€â”€ business-rules.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ examples/             # Example corrections
â”‚   â”œâ”€â”€ corrections.json  # General examples
â”‚   â””â”€â”€ patterns.json     # Pattern-specific examples
â””â”€â”€ scripts/              # Validation scripts
    â””â”€â”€ validate_extraction.py
```

## Learn more

- [iterata documentation](https://github.com/joelgombin/iterata)
- [Claude Code skills](https://docs.claude.com/claude-code)

---

*Generated on {datetime.now().strftime("%Y-%m-%d")} from {total_corrections} corrections*
"""
